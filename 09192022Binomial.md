## Quantal Release Case Study
All code is in MATLAB.

### Exercise 1
*Assume that there are 10 quanta available in a nerve terminal, and for a given release event each is released with a probability of 0.2. For one such event, what is the probability that 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, or 10 quanta will be released?*

In this case, probability of an event having n quanta with each with 0.2 release probability can be determined using a binomial distribution in which n = 10 and p = 0.2. 

Using the code below, a table can be generated giving the probabilities of having n quanta for a given release event. 

```
n = 10; %number of trials/possible quanta
p = 0.2; %probability of quantum release
x = [0:10]'; %array containing all possible numbers of releases x
Probabilities = [x binopdf(x,n,p)]; %compute release probabilities of each number of releases x. 
```

This yields a variable "Probabilities" that represents the release probabilities as below: 
```
x	Probability
0	0.107374182400000
1	0.268435456000000
2	0.301989888000000
3	0.201326592000000
4	0.0880803840000000
5	0.0264241152000000
6	0.00550502400000000
7	0.000786432000000000
8	7.37280000000001e-05
9	4.09599999999999e-06
10	1.02400000000000e-07
```

### Exercise 2
*Let's say you know that a given nerve terminal contains exactly 14 quanta available for release. You have read in the literature that the release probability of these quanta is low, say 0.1. To assess whether this value is reasonable, you run a simple experiment: activate the nerve and measure the number of quanta that are released. The result is 8 quanta. What is the probability that you would get this result (8 quanta) if the true probability of release really was 0.1?* 

This is given by the binomial probability density function, where n = 14, p = 0.1, x = 8, yielding 0.00001595917.

```
n = 14;
p = 0.1;
x = 8;

TrueProb = binopdf(x,n,p);
fprintf('%d',TrueProb)
```

*What about if the true release probability was much higher; say, 0.7?*

Use p = 0.7 instead of 0.1 in above expression, yielding 0.1262023.

```
n = 14;
p = 0.7;
x = 8;

TrueProb = binopdf(x,n,p);
fprintf('%d\n',TrueProb)

```



*What about for each decile of release probability (0.1, 0.2, ... 1.0)? Which value of release probability did you determine to be the most probable, given your measurement?*

```
n = 14;
p = [0:0.1:1]'; %generate array for values of p between 0 and 1 in 0.1 increments
x = 8;

Probabilities = [p binopdf(x,n,p)]; %compute probabiity of x quanta as a function of varying probabilities of quantum release
```

This yields a variable "Probabilities" that represents probability of exactly 8 quanta as a function of various probabilities of quantum release: 

```
p	Probability of 8 quanta
0	0
0.1	1.59591732300000e-05
0.2	0.00201527918592000
0.3	0.0231800095226701
0.4	0.0918211579084801
0.5	0.183288574218750
0.6	0.206597605294080
0.7	0.126202274067870
0.8	0.0322444669747200
0.9	0.00129269303163000
1	0
```

Thus, of the above values, the value of release probability value associated with the highest probability of 8 quanta is p = 0.6, with a probability of 8 quanta of 0.207. 

### Exercise 3 

*Not feeling convinced by your single experiment (good scientist!), you repeat it under identical conditions. This time you measure 5 quanta that were released. Your sample size has now doubled, to two measurements. You now want to take into account both measurements when you assess the likelihoods of different possible values of the underlying release probability. To do so, assume that the two measurements in this sample are independent of one another; that is, the value of each result had no bearing on the other. In this case, the total likelihood is simply the product of the likelihoods associated with each separate measurement. It is also typical to compute the logarithm of each likelihood and take their sum, which is often more convenient. What are the values of the total likelihood and total log-likelihood in this example, if we assume that the true release probability is 0.1?*

We now have two measurements, x = 8 and x = 5. The other parameters, n = 14, and p = 0.1, are identical to prior. 

Total Likelihood = 1.237819 x 10<sup>-7</sup>
Total Log Likelihood (using base 10) = -6.9073
 
```
n = 14;
p = 0.1;
Meas1 = 8;
Meas2 = 5;
Test = log10(TotalLikelihood);

TotalLikelihood = binopdf(Meas1,n,p) * binopdf(Meas2,n,p);
TotalLogLikelihood = log10(binopdf(Meas1,n,p)) + log10(binopdf(Meas2,n,p));
fprintf('Total Likelihood = %d\n',TotalLikelihood)
fprintf('Total Log Likelihood (using base 10) = %d\n',TotalLogLikelihood)

```

*Of course, knowing those values of the likelihood and log-likelihood is not particularly useful until you can compare them to the values computed for other possible values for the release probability, so you can determine which value of release probability is most likely, given the data. Therefore, compute the full likelihood and log-likelihood functions using deciles of release probability between 0 and 1. What is the maximum value?*

Use for loop below to compute range of total likelihoods and total log likelihoods of obtaining measurements of 8 and 5 across a range of values of p. 

```
n = 14;
p = 0;
Meas1 = 8;
Meas2 = 5;

TotalLikelihoods = zeros(1,3);

for p = 0.1:0.1:1
    TotalLikelihoods = [TotalLikelihoods; p (binopdf(Meas1,n,p)*binopdf(Meas2,n,p)) (log10(binopdf(Meas1,n,p)) + log10(binopdf(Meas2,n,p)))];
end
```

Yields the following TotalLikelihoods array: 

```
p	 TotalLikelihood	 TotalLogLikelihood
0	 0	 0
0.100000000000000	1.23781872149982e-07	-6.90734295306785
0.200000000000000	0.000173284275080635	-3.76124084614681
0.300000000000000	0.00455057542282909	-2.34193368308825
0.400000000000000	0.0189700313392216	-1.72193195163955
0.500000000000000	0.0223964676260948	-1.64982047324919
0.600000000000000	0.00843112503965403	-2.07411446975092
0.700000000000000	0.000835819975621667	-3.07788725367744
0.800000000000000	1.08302671925397e-05	-4.96536082880273
0.900000000000000	1.52817126111089e-09	-8.81582797194650
1	 0	 -Inf
```

The value of p at which likelihood of observing two different trials - one x = 8 and one x = 5 - is highest is given by the code below: 

```
TotalLikelihoods = array2table(TotalLikelihoods,'VariableNames',{'p','TotalLikelihood','TotalLogLikelihood'});
[~,maxlikeli] = max(TotalLikelihoods.TotalLikelihood);
TotalLikelihoods(maxlikeli,:)
```

This yields: 

```
     p     TotalLikelihood    TotalLogLikelihood
    ___    _______________    __________________

    0.5       0.022396             -1.6498      
```

To look at smaller increments, modify magnitude of steps in for loop, convert from array to table as above and select row with highest TotalLikelihood (i.e.., probability of observing 8 and 5): 

```
n = 14;
p = 0;
Meas1 = 8;
Meas2 = 5;

TotalLikelihoods = zeros(1,3);

for p = 0.1:0.0001:1
    TotalLikelihoods = [TotalLikelihoods; p (binopdf(Meas1,n,p)*binopdf(Meas2,n,p)) (log10(binopdf(Meas1,n,p)) + log10(binopdf(Meas2,n,p)))];
end

TotalLikelihoods = array2table(TotalLikelihoods,'VariableNames',{'p','TotalLikelihood','TotalLogLikelihood'});
[~,maxlikeli] = max(TotalLikelihoods.TotalLikelihood);
TotalLikelihoods(maxlikeli,:)
```

This yields p = 0.4643. 

```
      p       TotalLikelihood    TotalLogLikelihood
    ______    _______________    __________________

    0.4643       0.024056             -1.6188      
```

### Exercise 4

*You keep going and conduct 100 separate experiments and end up with the results given in the problem set. What is the most likely value of p, which we typically refer to as "p-hat" and represents the maximum-likelihood estimate of a parameter in the population given our sample with a resolution of 0.01?*

The mean of a binomial distribution is np; therefore p = mean/n, where n is the number of Bernoulli trials (opportunities for quantum release in this case). Calculate sample mean below and divide by number of Bernoulli trials to find p-hat: 

```
PSetArray = [0 0; 1 0; 2 3; 4 10; 5 19; 6 26; 7 16; 8 16; 9 5; 10 5; 11 0; 12 0; 13 0; 14 0];
PSetTable = array2table(PSetArray,'VariableNames',{'MeasuredReleases', 'Count'});
PSetTable.MeanComp = PSetTable.MeasuredReleases .* PSetTable.Count;
MeanSum = varfun(@sum,PSetTable(1:end,'MeanComp'));
MeanSum = table2array(MeanSum);
SampleMean = MeanSum/100;
Phat = SampleMean/14;
fprintf('P-hat is %d\n',Phat)
fprintf('Sample mean is %d\n', SampleMean)
```

P-hat is 0.451
Sample mean is 6.32.


### Exercise 5
*Let's say that you have run an exhaustive set of experiments on this synapse and have determined that the true release probability is 0.3 (within some very small tolerance). Now you want to test whether changing the temperature of the preparation affects the release probability. So you change the temperature, perform the experiment, and measure 7 quantal events for the same 14 available quanta. Compute p-hat.*

At this different temperature T2, we now have n = 1 data point of x = 7. Therefore, sample mean at T2 is 7, unlike the sample mean of 6.32 at the initial temperature T1. 

P-hat is therefore given by the this sample mean at T2 divided by the total number of available quanta. 7/14 = 0.5. 

*Standard statistical inference now asks the question, what is the probability that you would have obtained that measurement given a Null Hypothesis of no effect? In this case, no effect corresponds to an unchanged value of the true release probability (i.e., its value remained at 0.3 even with the temperature change). What is the probability that you would have gotten that measurement if your Null Hypothesis were true? Can you conclude that temperature had an effect?*

The question is Probability(Data | Null Hypothesis). The null hypothesis would be that p at T1 and T2 are not significantly different, i.e., come from the same distribution.

In other words, what is the probability of measuring 7 or more quantal events if p(T2) = 0.3? To answer this question, I will use a binomial cumulative distribution function to determine the complement of this probability, and then subtract that from 1 to determine my final answer. 

To compute the complement, I will let x = 6, since I am curious about the probability of 7 or more quantal events. I will let p = 0.3, and n = 14. 

```
x = 6; %because this is the complement
n = 14;
p = 0.3; %Because we are assuming for H0 that p(T1) = p(T2), i.e., that they are from same distribution 

Complement = binocdf(x, n, p);
fprintf('The complement is %f. ',Complement)
fprintf('Therefore, Probability(X>=7 | p(T1) = p(T2)), i.e., P(Data | Null Hypothesis) = %f.\n', (1-Complement))

```

The copmlement is 0.906718. Therefore, Probability (X>=7 | p(T1) = p(T2)), i.e., P(Data | Null Hypothesis) = 0.093282.





